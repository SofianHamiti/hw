{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the dataset and separate the labels from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Data2.csv')\n",
    "target = data['Target']\n",
    "features = data.drop('Target', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A18</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A24</th>\n",
       "      <th>A23</th>\n",
       "      <th>A22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1049</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2799</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>841</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2122</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2171</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  A1    A2  A3  A4  A5  A6  A7  A8  A9 ...   A15  A16  A17  A18  A19  \\\n",
       "0       1  18  1049  21   1   1   1   4   2   1 ...     4    3    1    3    1   \n",
       "1       1   9  2799  36   2   2   1   4   0   1 ...     2    3    1    3    1   \n",
       "2       1  12   841  23   1   1   2   2   9   2 ...     4    3    1    2    1   \n",
       "3       1  12  2122  39   2   2   1   4   0   1 ...     2    3    1    2    1   \n",
       "4       1  12  2171  38   2   1   1   4   0   1 ...     4    1    2    2    1   \n",
       "\n",
       "   A20  A21  A24  A23  A22  \n",
       "0    1    A    C    A    B  \n",
       "1    1    C    D    C    D  \n",
       "2    1    C    D    C    B  \n",
       "3    2    C    C    D    C  \n",
       "4    2    B    D    D    D  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our dataset is composed 1 numerical target and 22 features:\n",
    "\n",
    "- A21 to A24 features are of string categorical type. They will be encoded before training\n",
    "- A4 to A20 features are of integer type, probably categorical too, not sure.\n",
    "- A1 to A3 are numerical values and seem to be of different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### simple data quality check (missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1000 data points with 25 variables each\n",
      "The dataset has 0 missing value(s)\n"
     ]
    }
   ],
   "source": [
    "print ('The dataset has {0} data points with {1} variables each'.format(*data.shape))\n",
    "non_empty = len(features.dropna(axis='columns', how='all'))\n",
    "print('The dataset has {0} missing value(s)'.format(len(data) - non_empty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Descriptive statistics\n",
    "pd.describe() Generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A18</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.903000</td>\n",
       "      <td>3271.24800</td>\n",
       "      <td>35.54200</td>\n",
       "      <td>1.407000</td>\n",
       "      <td>1.155000</td>\n",
       "      <td>2.577000</td>\n",
       "      <td>2.54500</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>2.105000</td>\n",
       "      <td>3.384000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.68200</td>\n",
       "      <td>1.145000</td>\n",
       "      <td>2.358000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>1.928000</td>\n",
       "      <td>2.904000</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>1.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.058814</td>\n",
       "      <td>2822.75176</td>\n",
       "      <td>11.35267</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>1.257638</td>\n",
       "      <td>1.08312</td>\n",
       "      <td>2.744439</td>\n",
       "      <td>1.580023</td>\n",
       "      <td>1.208306</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>0.70808</td>\n",
       "      <td>0.477706</td>\n",
       "      <td>1.050209</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.530186</td>\n",
       "      <td>0.653614</td>\n",
       "      <td>0.490943</td>\n",
       "      <td>0.188856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.00000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.50000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.50000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.25000</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.00000</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A1           A2          A3           A4           A5  \\\n",
       "count  1000.000000   1000.00000  1000.00000  1000.000000  1000.000000   \n",
       "mean     20.903000   3271.24800    35.54200     1.407000     1.155000   \n",
       "std      12.058814   2822.75176    11.35267     0.577654     0.362086   \n",
       "min       4.000000    250.00000    19.00000     1.000000     1.000000   \n",
       "25%      12.000000   1365.50000    27.00000     1.000000     1.000000   \n",
       "50%      18.000000   2319.50000    33.00000     1.000000     1.000000   \n",
       "75%      24.000000   3972.25000    42.00000     2.000000     1.000000   \n",
       "max      72.000000  18424.00000    75.00000     4.000000     2.000000   \n",
       "\n",
       "                A6          A7           A8           A9          A10  \\\n",
       "count  1000.000000  1000.00000  1000.000000  1000.000000  1000.000000   \n",
       "mean      2.577000     2.54500     2.828000     2.105000     3.384000   \n",
       "std       1.257638     1.08312     2.744439     1.580023     1.208306   \n",
       "min       1.000000     0.00000     0.000000     1.000000     1.000000   \n",
       "25%       1.000000     2.00000     1.000000     1.000000     3.000000   \n",
       "50%       2.000000     2.00000     2.000000     1.000000     3.000000   \n",
       "75%       4.000000     4.00000     3.000000     3.000000     5.000000   \n",
       "max       4.000000     4.00000    10.000000     5.000000     5.000000   \n",
       "\n",
       "               A11         A12          A13          A14          A15  \\\n",
       "count  1000.000000  1000.00000  1000.000000  1000.000000  1000.000000   \n",
       "mean      2.973000     2.68200     1.145000     2.358000     2.845000   \n",
       "std       1.118715     0.70808     0.477706     1.050209     1.103718   \n",
       "min       1.000000     1.00000     1.000000     1.000000     1.000000   \n",
       "25%       2.000000     2.00000     1.000000     1.000000     2.000000   \n",
       "50%       3.000000     3.00000     1.000000     2.000000     3.000000   \n",
       "75%       4.000000     3.00000     1.000000     3.000000     4.000000   \n",
       "max       4.000000     4.00000     3.000000     4.000000     4.000000   \n",
       "\n",
       "               A16          A17          A18          A19          A20  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      2.675000     1.928000     2.904000     1.404000     1.037000  \n",
       "std       0.705601     0.530186     0.653614     0.490943     0.188856  \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "25%       3.000000     2.000000     3.000000     1.000000     1.000000  \n",
       "50%       3.000000     2.000000     3.000000     1.000000     1.000000  \n",
       "75%       3.000000     2.000000     3.000000     2.000000     1.000000  \n",
       "max       3.000000     3.000000     4.000000     2.000000     2.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = features._get_numeric_data().columns\n",
    "features[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A1 to A3 features seems indeed to be of different scales. This will be taken into consideration before training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Classes balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    700\n",
       "0    300\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our dataset classes are slightly imbalanced (2/3). \n",
    "This will be taken into consideration before training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_strings(data):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    return data.apply(le.fit_transform)\n",
    "    \n",
    "def scale_dataset(dataset): \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(dataset)\n",
    "    return pd.DataFrame(x_scaled)\n",
    "\n",
    "def train_rf(X, y):\n",
    "    param_grid = {'n_estimators': [5, 10, 15, 20, 30], 'max_depth': [2, 5, 7, 9, 11, 13, 15, 17, 19]}\n",
    "    \n",
    "    model = RandomForestClassifier(class_weight='balanced',random_state=12) \n",
    "    grid_model = GridSearchCV(model, param_grid, cv=5) \n",
    "    grid_model.fit(X, y)\n",
    "    return grid_model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predicted = model.predict(X_test)\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "string_features = features.select_dtypes(include=['object'])\n",
    "encoded_string_features = encode_strings(string_features)\n",
    "\n",
    "dataset = pd.concat([features[numerical_cols], encoded_string_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split the dataset into 70% training - 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I chose to train a random forest model. \n",
    "Some pros:\n",
    "- For many datasets, it produces a highly accurate classifier.\n",
    "- It gives estimates of what variables are important in the classification.\n",
    "- It has methods for balancing error in class population unbalanced datasets.\n",
    "\n",
    "Some cons:\n",
    "- Random forests have been observed to overfit for some datasets with noisy classification/regression tasks.\n",
    "- The classifications made by random forests are difficult for humans to interpret.\n",
    "- If the data contains groups of correlated features of similar relevance for the output, then smaller groups are favored over larger groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Process:\n",
    "\n",
    "I proceed with the class_weight=\"balanced\" mode.\n",
    "\n",
    "It automatically adjustd weights inversely proportional to class frequencies in the input data as: \n",
    "n_samples / (n_classes * np.bincount(y))\n",
    "\n",
    "This should help mitigating the imbalance of classes.\n",
    "\n",
    "The number and depth of trees hyperparameters are adjusted via a grid search.\n",
    "\n",
    "A 5-fold cross validation process is appplied during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are: {'max_depth': 19, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "grid_model = train_rf(X_train, y_train)\n",
    "print('The best hyperparameters are: {0}'.format(grid_model.best_params_))\n",
    "rf_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:0.763%\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 35  49]\n",
      " [ 22 194]]\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.42      0.50        84\n",
      "          1       0.80      0.90      0.85       216\n",
      "\n",
      "avg / total       0.75      0.76      0.75       300\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy:{0:.3f}%'.format(rf_model.score(X_test, y_test)))\n",
    "print(evaluate_model(rf_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The model acheives a decent overall accuracy.\n",
    "\n",
    "Howerver, the recall for class 0 - the least represented in the data - seems quite low.\n",
    "\n",
    "Oversampling the class 0, or better feature selection may help in the process.\n",
    "\n",
    "Scaling the data and chosing another training algorithm such as SVM could also be a good path for experimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### features with the most discriminative power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1128dcac8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAGDCAYAAADtZ0xmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112933eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_importance = pd.DataFrame(rf_model.feature_importances_, dataset.columns)\n",
    "features_importance.plot(kind='bar', \n",
    "                         title =\"features with the most discriminative power\", \n",
    "                         figsize=(12, 6), \n",
    "                         fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "A6, A2, A1, A3, and A8 are the top 5 most discriminative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
